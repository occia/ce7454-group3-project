{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE7454 2019 Project -- Group 3\n",
    "\n",
    "**Add the full name here**\n",
    "\n",
    "Please find all the models and data at [https://github.com/occia/ce7454-group3-project](https://github.com/occia/ce7454-group3-project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'etree' from 'lxml' (/usr/lib/python3/dist-packages/lxml/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8d92ed70a72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Declare top-level shortcuts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspiders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFormRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/spiders/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murl_is_from_spider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/http/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXmlRpcRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_request\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/http/request/form.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparsel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_root_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mw3lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstrip_html5_whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutableSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_setmixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSetMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'etree' from 'lxml' (/usr/lib/python3/dist-packages/lxml/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import urllib.request as urllib\n",
    "import scrapy\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "from random import randint\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Description\n",
    "\n",
    "Here briefly introduces the background, and throw out the 2 project questions:\n",
    "- How accurate the modern neural network models could be? (How to relate this with the Identity Acquisition?)\n",
    "- What's the performance of age authentication (below/above 18) for current neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Acquisition\n",
    "\n",
    "\n",
    "For the project, we prepare 2 kinds of data:\n",
    "- training data\n",
    "- validation/testing data\n",
    "\n",
    "#### Bechmark Data\n",
    "\n",
    "Due to the requirement of the large amount of labeled data, we merged 3 existing labeled benchmark datasets as our training data, including [All-Age-Faces](https://github.com/JingchunCheng/All-Age-Faces-Dataset), [FGNET](https://yanweifu.github.io/FG_NET_data/index.html), [UTK Face](https://susanqq.github.io/UTKFace).\n",
    "\n",
    "In total, the amount of labelled images from these 3 benchmarks is 38000, 32818 is used for training and 5182 is used for validation/testing.\n",
    "\n",
    "<span style=\"color:red\"> P: Should we mention that we selected the benchmark datasets for age classification? We can also insert the table from the papers about the bechmarks with their characteristics to justify our choice.</span>\n",
    "\n",
    "#### Real-world Data\n",
    "\n",
    "To validate the performance on the real-world data, we selected Instagram as a source for an additional dataset of unfiltered face images.\n",
    "We assumed that we may retrieve the age from bio and the actual image from the picture profile.\n",
    "\n",
    "##### Usernames Scraping \n",
    "\n",
    "As we intended to select the users from a particular country, we chose one influencer per country.\n",
    "We considered the following countries:\n",
    "\n",
    "European:\n",
    "* Australia - [@eddiebthe3rd](https://www.instagram.com/eddiebthe3rd/)\n",
    "* Canada - [@od_officiel](https://www.instagram.com/od_officiel/)\n",
    "* Germany - [@kontrak](https://www.instagram.com/kontrak/)\n",
    "* Russia - [@\\_agentgirl\\_](https://www.instagram.com/_agentgirl_/)\n",
    "\n",
    "Asian:\n",
    "* China - [@bingbing_fan](https://www.instagram.com/bingbing_fan/)\n",
    "* Indonesia - [@jokowi](http://instagram.com/jokowi)\n",
    "* India - [@narendramodi](http://instagram.com/narendramodi)\n",
    "\n",
    "Middle Eastern:\n",
    "* Iran - [@golfarahani](http://instagram.com/golfarahani)\n",
    "\n",
    "African:\n",
    "* Ethiopia - [@addisalem_getaneh](https://www.instagram.com/addisalem_getaneh/)\n",
    "* Nigeria - [@iambisola](https://www.instagram.com/iambisola)\n",
    "\n",
    "Hispanic:\n",
    "* Brazil - [@carlinhosmaiaof](https://www.instagram.com/carlinhosmaiaof/)\n",
    "\n",
    "To identify the necessary influencers we used websites such as [HypeAuditor](https://hypeauditor.com/top-instagram-all-australia/) and [Heepsy](https://www.heepsy.com/ranking/top-instagram-influencers-in-ethiopia) -- we have used it to get the information about the audience, as we were interested in the influencers with the audience which is at least 80% local.\n",
    "\n",
    "Instagram does not allow scrapping and detects spiders, so we used a third-party application for Instagram called [Imgtagram](https://imgtagram.com/followers/justinbieber). It also allows us to retrieve the usernames in a most efficient way. We also attempted to retrieve usernames by means of visual testing, i.e. Selenium, that imitates user behavior, but it was much slower. \n",
    "\n",
    "To do so, we opened a web page of a particular user's followers and scrolled down the page till the number of users shown reaches 125k. We ran <span style=\"color:red\"> the following JS script </span> in a developer's console of a browser:\n",
    "\n",
    "<pre>\n",
    "function scrapLinksAndScroll() {\n",
    "  window.scrollTo(0, document.body.scrollHeight);\n",
    "}\n",
    "\n",
    "setInterval(scrapLinksAndScroll, 3); </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Biography and Name Scraping\n",
    "After we collected the usernames, we applied a library called scrapy that allows to scrap the webpage content based on html elements.\n",
    "    scrapy allows us to do so in a multiprocessing way. The source code of a scraper looks as follows and requires a command <span style=\"color:red\"> scrapy crawl -o country.json </span>\n",
    "In this way, we write the collected data of users per country in a json file storing the information regarding their username, name, bio, country, and image URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We processed all the countries one by one as the data required careful validation.\n",
    "We showcase the data scraping process on a small (30 users) subset of Canadian instagram users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd scrapy/instascraper/instascraper/\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    country = 'canada'\n",
    "    name = \"profiles\"\n",
    "    file_path = '../../../data/test/usernames/%s.txt' %country\n",
    "    with open(file_path) as f:\n",
    "        start_urls = []\n",
    "        for u in f.readlines():\n",
    "            start_urls.append('https://imgtagram.com/u/' + u)\n",
    "\n",
    "    def parse(self, response):\n",
    "        country = 'canada'\n",
    "        for quote in response.css('div.text-block'):\n",
    "            yield {\n",
    "                'username': quote.css('h3::text').get(),\n",
    "                'name': quote.css('h1::text').get(),\n",
    "                'bio': quote.css('p.descp::text').get(),\n",
    "                'image': response.css('img.icon::attr(src)').get(),\n",
    "                'country': country\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting information is stored in a JSON file that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>bio</th>\n",
       "      <th>image</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@x_.bellita._x</td>\n",
       "      <td>bella❤️</td>\n",
       "      <td>None</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/02...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@_juliette_girard</td>\n",
       "      <td>Juliette Girard</td>\n",
       "      <td>None</td>\n",
       "      <td>https://scontent-sin2-1.cdninstagram.com/vp/fa...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@justine_marcoux10</td>\n",
       "      <td>Justine Marcoux</td>\n",
       "      <td>enjoy the little things🌞\\n_13 y/o\\n_🎿\\n_</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/fa...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@poutine_myra</td>\n",
       "      <td>Jerami🥰</td>\n",
       "      <td></td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/6f...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@coraliebillette</td>\n",
       "      <td>Coralie :)</td>\n",
       "      <td>Dancer💛\\n</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/8b...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@enyalachance._</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/07...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@rraaphb</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/eb...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@audreyann.paquet</td>\n",
       "      <td>Audrey-Ann Paquet</td>\n",
       "      <td>27 ans . Rimouski 🌼                           ...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/9d...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@marie_pierjolin</td>\n",
       "      <td>Marie-Pier Jolin</td>\n",
       "      <td>Une Pinkie heureuse 🌻</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/15...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>@lolobouu</td>\n",
       "      <td>🌹 LAURENCE. B</td>\n",
       "      <td>1997 | Nursing student | Gryffindor\\n🌿 Saguena...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/e1...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                name  \\\n",
       "0        @x_.bellita._x            bella❤️    \n",
       "1     @_juliette_girard    Juliette Girard    \n",
       "2    @justine_marcoux10    Justine Marcoux    \n",
       "3         @poutine_myra            Jerami🥰    \n",
       "4      @coraliebillette         Coralie :)    \n",
       "..                  ...                 ...   \n",
       "96      @enyalachance._                       \n",
       "97             @rraaphb                       \n",
       "98    @audreyann.paquet  Audrey-Ann Paquet    \n",
       "99     @marie_pierjolin   Marie-Pier Jolin    \n",
       "100           @lolobouu      🌹 LAURENCE. B    \n",
       "\n",
       "                                                   bio  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2           enjoy the little things🌞\\n_13 y/o\\n_🎿\\n_     \n",
       "3                                                        \n",
       "4                                           Dancer💛\\n    \n",
       "..                                                 ...   \n",
       "96                                                       \n",
       "97                                                None   \n",
       "98   27 ans . Rimouski 🌼                           ...   \n",
       "99                               Une Pinkie heureuse 🌻   \n",
       "100  1997 | Nursing student | Gryffindor\\n🌿 Saguena...   \n",
       "\n",
       "                                                 image country  \n",
       "0    https://scontent-cdg2-1.cdninstagram.com/vp/02...  canada  \n",
       "1    https://scontent-sin2-1.cdninstagram.com/vp/fa...  canada  \n",
       "2    https://scontent-cdg2-1.cdninstagram.com/vp/fa...  canada  \n",
       "3    https://scontent-cdg2-1.cdninstagram.com/vp/6f...  canada  \n",
       "4    https://scontent-cdg2-1.cdninstagram.com/vp/8b...  canada  \n",
       "..                                                 ...     ...  \n",
       "96   https://scontent-cdg2-1.cdninstagram.com/vp/07...  canada  \n",
       "97   https://scontent-cdg2-1.cdninstagram.com/vp/eb...  canada  \n",
       "98   https://scontent-cdg2-1.cdninstagram.com/vp/9d...  canada  \n",
       "99   https://scontent-cdg2-1.cdninstagram.com/vp/15...  canada  \n",
       "100  https://scontent-cdg2-1.cdninstagram.com/vp/e1...  canada  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles_path = './data/test/bio/%s.json' %country\n",
    "\n",
    "with open(input_path, 'r') as file:\n",
    "    user_profiles = json.load(file)\n",
    "    retrieved_profiles = pd.DataFrame.from_dict(user_profiles)\n",
    "\n",
    "retrieved_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering the bio\n",
    "\n",
    "To identify names and bios that contain age, we have used a regular expression that looks for the numbers in the aforementioned fields that meet the following requirements:\n",
    "\n",
    "* The previous symbol is not an alphanumeric character or an underscore, except for the case when the previous two symbols are represent a control sequence (\\n, \\t or \\r)\n",
    "* The number is either in range 1930-1999, or 2000-2019, or 10-99\n",
    "* The number is not followed by a digit\n",
    "\n",
    "\n",
    "When collecting our dataset, we also did manual checking to confirm the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>bio</th>\n",
       "      <th>image</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@_frederiquem</td>\n",
       "      <td>Frédérique Marceau ♧</td>\n",
       "      <td>19, St-Félicien, Québec 📍</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/a8...</td>\n",
       "      <td>canada</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@maude_montpetit</td>\n",
       "      <td>Maude 🌵</td>\n",
       "      <td>21 | 01.09.17 👼🏼💙 | 🐈🐈🐈🐈🐕🐕 |</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/66...</td>\n",
       "      <td>canada</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@daphhh.hamel</td>\n",
       "      <td>Daphh</td>\n",
       "      <td>18/05/19</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/8c...</td>\n",
       "      <td>canada</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mariiepierp21</td>\n",
       "      <td>marie-pier picard</td>\n",
       "      <td>20 ans\\n📚Cégep Garneau\\n🦷Finissante en hygiène...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/fc...</td>\n",
       "      <td>canada</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@camybr_</td>\n",
       "      <td>CAMILLE</td>\n",
       "      <td>23 | 🔒 | UQAC 🧠</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/af...</td>\n",
       "      <td>canada</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@1997kakou</td>\n",
       "      <td>Karel Soucy</td>\n",
       "      <td>22ans 💁‍♀️                                    ...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/65...</td>\n",
       "      <td>canada</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@annesosimo</td>\n",
       "      <td>𝒜𝓃𝓃𝑒-𝒮𝑜</td>\n",
       "      <td>16yo | ☁️🥥⛓✉️🖇💭\\n</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/41...</td>\n",
       "      <td>canada</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@alyson_cote</td>\n",
       "      <td>aly ♡</td>\n",
       "      <td>18 || csf\\n🥰🌞😙✌</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/0a...</td>\n",
       "      <td>canada</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@tiffounne</td>\n",
       "      <td>Tiffany ✴</td>\n",
       "      <td>26 | B.Sc. Kinésiologie | M.Sc. Ergonomie</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/47...</td>\n",
       "      <td>canada</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@coralie.sav</td>\n",
       "      <td>Coralie Savard</td>\n",
       "      <td>19/08/02 ❤️ Sc:coralie_sav</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/21...</td>\n",
       "      <td>canada</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@audreyann.paquet</td>\n",
       "      <td>Audrey-Ann Paquet</td>\n",
       "      <td>27 ans . Rimouski 🌼                           ...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/9d...</td>\n",
       "      <td>canada</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@lolobouu</td>\n",
       "      <td>🌹 LAURENCE. B</td>\n",
       "      <td>1997 | Nursing student | Gryffindor\\n🌿 Saguena...</td>\n",
       "      <td>https://scontent-cdg2-1.cdninstagram.com/vp/e1...</td>\n",
       "      <td>canada</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                   name  \\\n",
       "0       @_frederiquem  Frédérique Marceau ♧    \n",
       "1    @maude_montpetit               Maude 🌵    \n",
       "2       @daphhh.hamel                 Daphh    \n",
       "3      @mariiepierp21     marie-pier picard    \n",
       "4            @camybr_               CAMILLE    \n",
       "5          @1997kakou           Karel Soucy    \n",
       "6         @annesosimo               𝒜𝓃𝓃𝑒-𝒮𝑜    \n",
       "7        @alyson_cote                 aly ♡    \n",
       "8          @tiffounne             Tiffany ✴    \n",
       "9        @coralie.sav        Coralie Savard    \n",
       "10  @audreyann.paquet     Audrey-Ann Paquet    \n",
       "11          @lolobouu         🌹 LAURENCE. B    \n",
       "\n",
       "                                                  bio  \\\n",
       "0                           19, St-Félicien, Québec 📍   \n",
       "1                        21 | 01.09.17 👼🏼💙 | 🐈🐈🐈🐈🐕🐕 |   \n",
       "2                                          18/05/19     \n",
       "3   20 ans\\n📚Cégep Garneau\\n🦷Finissante en hygiène...   \n",
       "4                                     23 | 🔒 | UQAC 🧠   \n",
       "5   22ans 💁‍♀️                                    ...   \n",
       "6                                  16yo | ☁️🥥⛓✉️🖇💭\\n    \n",
       "7                                     18 || csf\\n🥰🌞😙✌   \n",
       "8           26 | B.Sc. Kinésiologie | M.Sc. Ergonomie   \n",
       "9                        19/08/02 ❤️ Sc:coralie_sav     \n",
       "10  27 ans . Rimouski 🌼                           ...   \n",
       "11  1997 | Nursing student | Gryffindor\\n🌿 Saguena...   \n",
       "\n",
       "                                                image country age  \n",
       "0   https://scontent-cdg2-1.cdninstagram.com/vp/a8...  canada  19  \n",
       "1   https://scontent-cdg2-1.cdninstagram.com/vp/66...  canada  21  \n",
       "2   https://scontent-cdg2-1.cdninstagram.com/vp/8c...  canada  18  \n",
       "3   https://scontent-cdg2-1.cdninstagram.com/vp/fc...  canada  20  \n",
       "4   https://scontent-cdg2-1.cdninstagram.com/vp/af...  canada  23  \n",
       "5   https://scontent-cdg2-1.cdninstagram.com/vp/65...  canada  22  \n",
       "6   https://scontent-cdg2-1.cdninstagram.com/vp/41...  canada  16  \n",
       "7   https://scontent-cdg2-1.cdninstagram.com/vp/0a...  canada  18  \n",
       "8   https://scontent-cdg2-1.cdninstagram.com/vp/47...  canada  26  \n",
       "9   https://scontent-cdg2-1.cdninstagram.com/vp/21...  canada  19  \n",
       "10  https://scontent-cdg2-1.cdninstagram.com/vp/9d...  canada  27  \n",
       "11  https://scontent-cdg2-1.cdninstagram.com/vp/e1...  canada  22  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "filtered_profiles = []\n",
    "\n",
    "input_path = './data/test/bio/%s.json' %country\n",
    "output_path = './data/test/bio/filtered/%s.json' %country\n",
    "\n",
    "with open(input_path, 'r') as file:\n",
    "    user_profiles = json.load(file)\n",
    "    for user in user_profiles:\n",
    "        if user['bio'] and user['bio'] != ' ':\n",
    "            year_pattern = re.compile(\"(?:(?<!\\w)|(?<=\\\\[ntr]))(19[3-9]\\d|20[01]\\d)(?!\\d)\")\n",
    "            age_pattern = re.compile(\"(?:(?<!\\w)|(?<=\\\\[ntr]))([1-9]\\d)(?!\\d)\")\n",
    "            birth_year_bio = year_pattern.match(user['bio'])\n",
    "            str_name = str(user['name'])\n",
    "            birth_year_name = year_pattern.match(str_name)\n",
    "            age_bio = age_pattern.match(user['bio'])\n",
    "            age_name = age_pattern.match(str_name)\n",
    "\n",
    "            if birth_year_bio:\n",
    "                year = birth_year_bio.group(1)\n",
    "                age = 2019 - int(year)\n",
    "                user['age'] = str(age)\n",
    "                filtered_profiles.append(user)\n",
    "            elif birth_year_name:\n",
    "                year = birth_year_name.group(1)\n",
    "                age = 2019 - int(year)\n",
    "                user['age'] = str(age)\n",
    "                filtered_profiles.append(user)\n",
    "            elif age_bio:\n",
    "                user['age'] = age_bio.group(1)\n",
    "                filtered_profiles.append(user)\n",
    "            elif age_name:\n",
    "                user['age'] = age_name.group(1)\n",
    "                filtered_profiles.append(user)\n",
    "                \n",
    "with open(output_path, 'w') as outfile:\n",
    "    json.dump(filtered_profiles, outfile)\n",
    "    \n",
    "age_profiles = pd.DataFrame.from_dict(filtered_profiles)\n",
    "age_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scraping the profile pictures\n",
    "\n",
    "For the collected users having a bio valid with respect to the regex described above, we then downloaded the profile pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing users of canada\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n",
      "Downloading image\n"
     ]
    }
   ],
   "source": [
    "# image retrieval\n",
    "def url_to_image(url):\n",
    "    resp = urllib.urlopen(url)\n",
    "    return resp\n",
    "\n",
    "profiles_path = './data/test/bio/filtered/%s.json' %country\n",
    "img_path = './data/test/images/%s/' %country\n",
    "parsed_users = []\n",
    "\n",
    "print('Parsing users of', country)\n",
    "\n",
    "# profiles JSON parsing\n",
    "with open(profiles_path, 'r') as file:\n",
    "    user_profiles = json.load(file)\n",
    "    for usr in user_profiles[0:]:\n",
    "        url = usr['image']\n",
    "        username = usr['username']\n",
    "        image_path = img_path + username + '.jpg'\n",
    "    # download the image URL\n",
    "        if url != '':\n",
    "            print (\"Downloading image\")\n",
    "            image = url_to_image(url)\n",
    "            f = open(image_path,'wb')\n",
    "            f.write(image.read())\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Exploration\n",
    "\n",
    "// **add the age distribution graph for 38000**\n",
    "\n",
    "// **add the age distribution graph for 1900+ instagram data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution for Instagram\n",
    "\n",
    "image_nums = {}\n",
    "image_nums_all = {}\n",
    "\n",
    "for i in range(1,101):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    if i < 10:\n",
    "        i = '0' + str(i)\n",
    "        \n",
    "    # Fix the path and variables\n",
    "    data_dir = './data/processed/merged_raw/%s/' %i\n",
    "    if os.path.exists(data_dir):\n",
    "        os.listdir(data_dir)\n",
    "        image_num = len([name for name in os.listdir(data_dir)])\n",
    "        i = int(i)\n",
    "        image_nums[i] = image_num\n",
    "        image_nums_all[i] = image_num\n",
    "    else: \n",
    "        i = int(i)\n",
    "        image_nums_all[i] = 0\n",
    "        \n",
    "print(image_nums)\n",
    "vals = image_nums\n",
    "lists = sorted(image_nums_all.items()) \n",
    "x, y = zip(*lists)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Validation\n",
    "\n",
    "To perform the validation we used the opencv trained model for face detection. We ran the detection algorithm on all the collected images to eliminate the pictures which contain more or less than one face as shown below.\n",
    "Apart from face detection, the network also cuts the faces from the picture.\n",
    "We (after some more manual verification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test/images/canada/@camybr_.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@mariiepierp21.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@maude_montpetit.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@coralie.sav.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@tiffounne.jpg\n",
      "No face Detected, Checking next frame\n",
      "no face detected\n",
      "./data/test/images/canada/@audreyann.paquet.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@daphhh.hamel.jpg\n",
      "No face Detected, Checking next frame\n",
      "no face detected\n",
      "./data/test/images/canada/@_frederiquem.jpg\n",
      "that is a couple\n",
      "./data/test/images/canada/@annesosimo.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@alyson_cote.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@1997kakou.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@lolobouu.jpg\n",
      "that is a couple\n",
      "./data/test/images/canada/@camybr_.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@mariiepierp21.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@maude_montpetit.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@coralie.sav.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@audreyann.paquet.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@annesosimo.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@alyson_cote.jpg\n",
      "there is one face\n",
      "./data/test/images/canada/@1997kakou.jpg\n",
      "there is one face\n"
     ]
    }
   ],
   "source": [
    "from face_utils import getFaces\n",
    "from os import walk\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_path = './data/test/images/%s' %country\n",
    "\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(image_path):\n",
    "    for image in filenames:        \n",
    "        username = image.split('.jpg')[0].split('/')\n",
    "        name = username[len(username) - 1]        \n",
    "        save_path = './data/test/images/%s/cut/%s.jpg' %(country,name)\n",
    "        path = image_path + '/' + image\n",
    "        print(path)\n",
    "        faces = getFaces(path)\n",
    "        if faces == 0:\n",
    "            print('no face detected')\n",
    "        elif len(faces) == 2:\n",
    "            print('that is a couple')\n",
    "        elif len(faces) == 1:\n",
    "            print('there is one face') \n",
    "            cv.imwrite(save_path, faces[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Preprocessing\n",
    "\n",
    "// **this section should describe the bin-size splitting thing, section 3 will use that**\n",
    "\n",
    "// **it should also contain Instagram data labelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test/result/21_2_@maude_montpetit.jpg\n",
      "./data/test/result/20_2_@mariiepierp21.jpg\n",
      "./data/test/result/23_2_@camybr_.jpg\n",
      "./data/test/result/22_2_@1997kakou.jpg\n",
      "./data/test/result/16_2_@annesosimo.jpg\n",
      "./data/test/result/18_2_@alyson_cote.jpg\n",
      "./data/test/result/19_2_@coralie.sav.jpg\n",
      "./data/test/result/27_2_@audreyann.paquet.jpg\n"
     ]
    }
   ],
   "source": [
    "# Countries indexes mapping\n",
    "\n",
    "countries = {\n",
    "    \"australia\": \"0\",\n",
    "    \"brazil\": \"1\",\n",
    "    \"canada\": \"2\",\n",
    "    \"china\": \"3\",\n",
    "    \"ethiopia\": \"4\",\n",
    "    \"nigeria\": \"4\",\n",
    "    \"germany\": \"5\",\n",
    "    \"india\": \"6\",\n",
    "    \"indonesia\": \"7\",\n",
    "    \"iran\": \"8\",\n",
    "    \"russia\": \"9\"\n",
    "}\n",
    "\n",
    "image_path = './data/test/images/%s/cut/' %country\n",
    "data_path = './data/test/bio/filtered/%s.json' %country\n",
    "result_path = './data/test/result'\n",
    "\n",
    "with open(data_path, 'r') as file:\n",
    "    user_profiles = json.load(file)\n",
    "    for user in user_profiles:\n",
    "        username = user['username']\n",
    "        age = user['age']\n",
    "        country_index = countries[country]\n",
    "        \n",
    "        image = image_path + username + '.jpg'\n",
    "        \n",
    "        if os.path.exists(image):\n",
    "        # The new name is 'age_country_username'\n",
    "            new_name = '%s/%s_%s_%s.jpg' %(result_path, age, country_index, username)\n",
    "            print(new_name)\n",
    "            os.rename(image, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models and Training\n",
    "\n",
    "In this section, we discuss the choosen models, the training configurations for each model, and the whole training pipeline. The outputs of this section are the saved trained weights for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Selection\n",
    "\n",
    "We targeted on 3 representative models in face recognition and age prediction, the MLP, VGG, and ResNet.\n",
    "\n",
    "As there are many variants of these networks, the first thing is to determine which variants of these model are suitable for our project. \n",
    "We probed ResNet18, ResNet50, ResNet152 using parts of the training data (around 10,000) and found that the performance has no big difference. \n",
    "Thus we made the following selection:\n",
    "- ResNet18, resnet with 18 layers\n",
    "- VGG19_bn, vgg 19 layers with batch normalization\n",
    "- MLP18, 18-layer mlp\n",
    "\n",
    "The ResNet and VGG models can directly imported using the following statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision.models import vgg19_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the MLP model is implemented by ourself and you can find it in the `./src/neural_network/mlp.py` in the [project github](https://github.com/occia/ce7454-group3-project).\n",
    "\n",
    "For demo usage, here is a smaller version MLP implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class is for demo use\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size2, hidden_size3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size3, hidden_size4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size4, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Training Parameters Setup\n",
    "\n",
    "We keep the following training configuration for all 3 choosen models:\n",
    "- Learning Rate, the initial value of learning rate is set as `0.001`\n",
    "- Optimizer, using **Adam** rather than **SGD**\n",
    "- Criterion, using `torch.nn.CrossEntropyLoss()`\n",
    "- Epoches, set to 50 as it balances the training time costs and the training consequence\n",
    "- Batch size, set as 256\n",
    "- Image pixels, set as `(3, 200, 200)`, 3 means 3 channels (a.k.a colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# training parameters setup for demo use\n",
    "#\n",
    "\n",
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "\n",
    "channels = 3\n",
    "img_pixels = (200,200)\n",
    "lr = 0.001\n",
    "num_epochs = 2\n",
    "batch_size = 128\n",
    "\n",
    "# loading dataset\n",
    "def loading_dataset(train_dataset, test_dataset):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_pixels),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    img_data_train = torchvision.datasets.ImageFolder(root=train_dataset, transform=transform)\n",
    "    data_loader_train = torch.utils.data.DataLoader(img_data_train, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    img_data_val = torchvision.datasets.ImageFolder(root=test_dataset, transform=transform)\n",
    "    data_loader_val = torch.utils.data.DataLoader(img_data_val, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = data_loader_train\n",
    "    dataloaders['val'] = data_loader_val\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Model Training WorkFlow\n",
    "\n",
    "The workflow is based on the template teacher provided in the class, and is improved in some aspects.\n",
    "\n",
    "Here lists the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# main training workflow\n",
    "#\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    last = since\n",
    "    time_elapsed = since\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            time_elapsed = time.time() - last\n",
    "            last = time.time()\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Time: {:.0f}m {:.0f}s'.format(phase, epoch_loss, epoch_acc, time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "            # deep copy the modeltopk\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the networks are initialized randomly.\n",
    "Also the images of the dataset are shuffled every time.\n",
    "The key different parts of our implementation from the teacher's template are:\n",
    "- we do train & validation for every epoch\n",
    "- based on the validation result, we save the best epoch's weights, and return that instead of the one be trained longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training Pipeline\n",
    "\n",
    "Till now, we know which model to train and how to train a model. To answer the questions we raised at the beginning, we need to train all the combinations of the selected models and the prepared datasets.\n",
    "\n",
    "Thus, the next step is building the training pipeline for all training combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download demo dataset\n",
    "#!wget -nc \"https://somelink\"\n",
    "#!ls\n",
    "#!tar xf ce7454_demo_dataset.tar.gz\n",
    "#!ls dataset\n",
    "#!mkdir -p ./saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training_and_save_model(net, num_epochs, model_save_name):\n",
    "    net = net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr)\n",
    "    net, _ = train_model(net, dataloaders, criterion, optimizer, num_epochs)\n",
    "    torch.save(net.state_dict(), os.path.join(\"./saved_models/\", model_save_name))\n",
    "\n",
    "#\n",
    "# whole training pipeline\n",
    "#\n",
    "print(\"[+] This training pipeline is for demo usage\")\n",
    "for binsize in [1, 6, 10]:\n",
    "    classes = int((100 + binsize - 1) / binsize)\n",
    "    \n",
    "    dataloaders = loading_dataset(\"./dataset/demo_train_bin_%d\" % (binsize), \"./dataset/demo_test_bin_%d\" % (binsize))\n",
    "    \n",
    "    for model in [\"MLP\", \"ResNet\", \"VGG\"]:\n",
    "        print(\"[+] Training for %s with binsize %d dataset started\" % (model, binsize))\n",
    "        \n",
    "        if model == \"MLP\":\n",
    "            net = MLP(channels * img_pixels[0] * img_pixels[1], 512, 512, 512, 512, classes)\n",
    "        elif model == \"ResNet\":\n",
    "            net = resnet18(num_classes=classes)\n",
    "            # comment this as this is a demo\n",
    "            #continue\n",
    "        else:\n",
    "            net = vgg19_bn(num_classes=classes)\n",
    "            # comment this as this is a demo\n",
    "            #continue\n",
    "        \n",
    "        model_save_name = \"%s_%s_demo_merged_train_bin%d\" % (num_epochs, net.__class__.__name__, binsize)\n",
    "        training_and_save_model(net, num_epochs, model_save_name)\n",
    "\n",
    "        print(\"[+] Training for %s with binsize %d dataset done\" % (model, binsize))\n",
    "\n",
    "        del net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the pipeline code, we saved weights of the best epoch for all the models towards all the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1 Accuracy Comparison Among Models\n",
    "\n",
    "### 4.2 Identity Acquision Accuracy Cross Ages\n",
    "\n",
    "### 4.3 Age Authentication For 18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
