{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V61QIg_fESFb"
   },
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bH3hipNnESFd"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13671,
     "status": "ok",
     "timestamp": 1572664098050,
     "user": {
      "displayName": "张岑",
      "photoUrl": "",
      "userId": "13574495303828231786"
     },
     "user_tz": -480
    },
    "id": "5D6Vt4gLESFe",
    "outputId": "76b553bc-1361-43c9-96fd-0f17d40bbd65"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'ce7454_training_pipeline.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oyqJCEzcESFh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5xBIKb2ESFj"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instagram_merged_expr_bin_1   test_part_utk_merged_expr_bin_1\r\n",
      "instagram_merged_expr_bin_10  test_part_utk_merged_expr_bin_10\r\n",
      "instagram_merged_expr_bin_3   test_part_utk_merged_expr_bin_3\r\n",
      "instagram_merged_expr_bin_6   test_part_utk_merged_expr_bin_6\r\n",
      "instagram_merged_raw\t      test_part_utk_merged_raw\r\n",
      "make_bin_dataset.sh\t      us.zip\r\n",
      "test_part_utk.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset \n",
    "!mkdir -p ./outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, \n",
    "                 hidden_size3, hidden_size4, hidden_size5, \n",
    "                 hidden_size6, hidden_size7, hidden_size8,\n",
    "                 hidden_size9, hidden_size10, hidden_size11, \n",
    "                 hidden_size12, hidden_size13, hidden_size14, \n",
    "                 hidden_size15, hidden_size16, hidden_size17, \n",
    "                 output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size2, hidden_size3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size3, hidden_size4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size4, hidden_size5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size5, hidden_size6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size6, hidden_size7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size7, hidden_size8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size8, hidden_size9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size9, hidden_size10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size10, hidden_size11),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size11, hidden_size12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size12, hidden_size13),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size13, hidden_size14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size14, hidden_size15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size15, hidden_size16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size16, hidden_size17),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size17, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4HbxVhJfLbj"
   },
   "source": [
    "### Gen the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L04boyCrfK_A",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gen_pickle(binsize, model_name):\n",
    "    #\n",
    "    # cpu or gpu\n",
    "    #\n",
    "    #device = torch.device(\"cuda\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    #\n",
    "    # dataset\n",
    "    #\n",
    "    expr_dataset = dict_data[binsize]\n",
    "    img_pixels = (200, 200)\n",
    "    channels = 3\n",
    "\n",
    "    classes = dict_class[binsize]\n",
    "    print(\"classes: \", classes)\n",
    "\n",
    "    #\n",
    "    # load the dataset\n",
    "    #\n",
    "    transform = transforms.Compose([\n",
    "        # TODO: check this more later\n",
    "        #transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(img_pixels),\n",
    "        transforms.ToTensor()])\n",
    "    img_data_expr = ImageFolderWithPaths(root=expr_dataset, transform=transform)\n",
    "    data_loader_expr = torch.utils.data.DataLoader(img_data_expr, batch_size=1,shuffle=False)\n",
    "\n",
    "    #\n",
    "    # load the model parameters\n",
    "    #\n",
    "    if model_name == \"MLP\":\n",
    "        net = dict_net[model_name](channels * img_pixels[0] * img_pixels[1], 512, 512,\n",
    "                                   512, 512, 512, 512, 512, 512, 512, 512, 512, 512,\n",
    "                                   512, 512, 512, 512, 512, classes)\n",
    "    else:\n",
    "        net = dict_net[model_name](num_classes=classes)\n",
    "    net.load_state_dict(torch.load(dict_model[binsize]))\n",
    "    net.eval()\n",
    "\n",
    "    #\n",
    "    # get prediction results & parsing the img name\n",
    "    #\n",
    "    label_dict = dict(map(reversed, img_data_expr.class_to_idx.items()))\n",
    "    print(label_dict)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for inputs, labels, paths in data_loader_expr:\n",
    "        path, label, image = paths[0], labels.tolist()[0], inputs.tolist()[0]\n",
    "        probs_tensor = net(inputs)\n",
    "        probs = F.softmax(probs_tensor, dim=1)\n",
    "        probs = probs.tolist()[0]\n",
    "\n",
    "        #print('path:\\t\\t\\t', path)\n",
    "        #print('right label:\\t\\t', label_dict[label])\n",
    "        #print(input.size())\n",
    "        #print(image.size())\n",
    "        #plt.imshow(trans(image))\n",
    "        #print('predicted label:\\t', label_dict[probs.index(max(probs))])\n",
    "        #print('probs:\\t\\t', probs)\n",
    "\n",
    "        output.append({\"path\": path,\n",
    "                        \"name\": os.path.basename(path),\n",
    "                        \"label-str\": label_dict[label], \n",
    "                        \"pred-label-str\": label_dict[probs.index(max(probs))],\n",
    "                        \"label-num\": label, \n",
    "                        \"pred-label-num\": probs.index(max(probs)),\n",
    "                        \"probs\":probs,})\n",
    "        #break\n",
    "\n",
    "    print(len(output))\n",
    "    with open( dict_output[binsize], \"wb\" ) as f:\n",
    "        pickle.dump(output, f)\n",
    "\n",
    "    # load thing\n",
    "    # with open( \"save.p\", \"rb\" ) as f:\n",
    "    #    output = pickle.load( f )\n",
    "    #\n",
    "\n",
    "    # do bin 3 \n",
    "    # do pickle for aoutput\n",
    "    print(\"bin %d finished\" % (binsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RuApj7-sESF7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "classes:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/cuda/__init__.py:135: UserWarning: \n",
      "    Found GPU0 Quadro K2000 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'age00to00', 1: 'age01to01', 2: 'age02to02', 3: 'age03to03', 4: 'age04to04', 5: 'age05to05', 6: 'age06to06', 7: 'age07to07', 8: 'age08to08', 9: 'age09to09', 10: 'age10to10', 11: 'age11to11', 12: 'age12to12', 13: 'age13to13', 14: 'age14to14', 15: 'age15to15', 16: 'age16to16', 17: 'age17to17', 18: 'age18to18', 19: 'age19to19', 20: 'age20to20', 21: 'age21to21', 22: 'age22to22', 23: 'age23to23', 24: 'age24to24', 25: 'age25to25', 26: 'age26to26', 27: 'age27to27', 28: 'age28to28', 29: 'age29to29', 30: 'age30to30', 31: 'age31to31', 32: 'age32to32', 33: 'age33to33', 34: 'age34to34', 35: 'age35to35', 36: 'age36to36', 37: 'age37to37', 38: 'age38to38', 39: 'age39to39', 40: 'age40to40', 41: 'age41to41', 42: 'age42to42', 43: 'age43to43', 44: 'age44to44', 45: 'age45to45', 46: 'age46to46', 47: 'age47to47', 48: 'age48to48', 49: 'age49to49', 50: 'age50to50', 51: 'age51to51', 52: 'age52to52', 53: 'age53to53', 54: 'age54to54', 55: 'age55to55', 56: 'age56to56', 57: 'age57to57', 58: 'age58to58', 59: 'age59to59', 60: 'age60to60', 61: 'age61to61', 62: 'age62to62', 63: 'age63to63', 64: 'age64to64', 65: 'age65to65', 66: 'age66to66', 67: 'age67to67', 68: 'age68to68', 69: 'age69to69', 70: 'age70to70', 71: 'age71to71', 72: 'age72to72', 73: 'age73to73', 74: 'age74to74', 75: 'age75to75', 76: 'age76to76', 77: 'age77to77', 78: 'age78to78', 79: 'age79to79', 80: 'age80to80', 81: 'age81to81', 82: 'age82to82', 83: 'age83to83', 84: 'age84to84', 85: 'age85to85', 86: 'age86to86', 87: 'age87to87', 88: 'age88to88', 89: 'age89to89', 90: 'age90to90', 91: 'age91to91', 92: 'age92to92', 93: 'age93to93', 94: 'age94to94', 95: 'age95to95', 96: 'age96to96', 97: 'age97to97', 98: 'age98to98', 99: 'age99to99'}\n",
      "1908\n",
      "bin 1 finished\n",
      "cpu\n",
      "classes:  17\n",
      "{0: 'age00to05', 1: 'age06to11', 2: 'age12to17', 3: 'age18to23', 4: 'age24to29', 5: 'age30to35', 6: 'age36to41', 7: 'age42to47', 8: 'age48to53', 9: 'age54to59', 10: 'age60to65', 11: 'age66to71', 12: 'age72to77', 13: 'age78to83', 14: 'age84to89', 15: 'age90to95', 16: 'age96to101'}\n",
      "1908\n",
      "bin 6 finished\n",
      "cpu\n",
      "classes:  10\n",
      "{0: 'age00to09', 1: 'age10to19', 2: 'age20to29', 3: 'age30to39', 4: 'age40to49', 5: 'age50to59', 6: 'age60to69', 7: 'age70to79', 8: 'age80to89', 9: 'age90to99'}\n",
      "1908\n",
      "bin 10 finished\n",
      "cpu\n",
      "classes:  100\n",
      "{0: 'age00to00', 1: 'age01to01', 2: 'age02to02', 3: 'age03to03', 4: 'age04to04', 5: 'age05to05', 6: 'age06to06', 7: 'age07to07', 8: 'age08to08', 9: 'age09to09', 10: 'age10to10', 11: 'age11to11', 12: 'age12to12', 13: 'age13to13', 14: 'age14to14', 15: 'age15to15', 16: 'age16to16', 17: 'age17to17', 18: 'age18to18', 19: 'age19to19', 20: 'age20to20', 21: 'age21to21', 22: 'age22to22', 23: 'age23to23', 24: 'age24to24', 25: 'age25to25', 26: 'age26to26', 27: 'age27to27', 28: 'age28to28', 29: 'age29to29', 30: 'age30to30', 31: 'age31to31', 32: 'age32to32', 33: 'age33to33', 34: 'age34to34', 35: 'age35to35', 36: 'age36to36', 37: 'age37to37', 38: 'age38to38', 39: 'age39to39', 40: 'age40to40', 41: 'age41to41', 42: 'age42to42', 43: 'age43to43', 44: 'age44to44', 45: 'age45to45', 46: 'age46to46', 47: 'age47to47', 48: 'age48to48', 49: 'age49to49', 50: 'age50to50', 51: 'age51to51', 52: 'age52to52', 53: 'age53to53', 54: 'age54to54', 55: 'age55to55', 56: 'age56to56', 57: 'age57to57', 58: 'age58to58', 59: 'age59to59', 60: 'age60to60', 61: 'age61to61', 62: 'age62to62', 63: 'age63to63', 64: 'age64to64', 65: 'age65to65', 66: 'age66to66', 67: 'age67to67', 68: 'age68to68', 69: 'age69to69', 70: 'age70to70', 71: 'age71to71', 72: 'age72to72', 73: 'age73to73', 74: 'age74to74', 75: 'age75to75', 76: 'age76to76', 77: 'age77to77', 78: 'age78to78', 79: 'age79to79', 80: 'age80to80', 81: 'age81to81', 82: 'age82to82', 83: 'age83to83', 84: 'age84to84', 85: 'age85to85', 86: 'age86to86', 87: 'age87to87', 88: 'age88to88', 89: 'age89to89', 90: 'age90to90', 91: 'age91to91', 92: 'age92to92', 93: 'age93to93', 94: 'age94to94', 95: 'age95to95', 96: 'age96to96', 97: 'age97to97', 98: 'age98to98', 99: 'age99to99'}\n",
      "4792\n",
      "bin 1 finished\n",
      "cpu\n",
      "classes:  17\n",
      "{0: 'age00to05', 1: 'age06to11', 2: 'age12to17', 3: 'age18to23', 4: 'age24to29', 5: 'age30to35', 6: 'age36to41', 7: 'age42to47', 8: 'age48to53', 9: 'age54to59', 10: 'age60to65', 11: 'age66to71', 12: 'age72to77', 13: 'age78to83', 14: 'age84to89', 15: 'age90to95', 16: 'age96to101'}\n",
      "4792\n",
      "bin 6 finished\n",
      "cpu\n",
      "classes:  10\n",
      "{0: 'age00to09', 1: 'age10to19', 2: 'age20to29', 3: 'age30to39', 4: 'age40to49', 5: 'age50to59', 6: 'age60to69', 7: 'age70to79', 8: 'age80to89', 9: 'age90to99'}\n",
      "4792\n",
      "bin 10 finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ResNet or VGG or MLP\n",
    "#model_name = \"VGG\"\n",
    "#model_name = \"ResNet\"\n",
    "#model_name = \"MLP\"\n",
    "\n",
    "dict_class = {}\n",
    "dict_model = {}\n",
    "dict_data = {}\n",
    "dict_output = {}\n",
    "dict_net = {}\n",
    "\n",
    "#for model_name in [\"ResNet\", \"VGG\", \"MLP\"]:\n",
    "for model_name in [\"MLP\"]:\n",
    "    for dataset in [\"instagram\", \"test_part_utk\"]:\n",
    "    #for dataset in [\"instagram\"]:\n",
    "        dict_class = {1:100, \n",
    "                      3:34, \n",
    "                      6:17, \n",
    "                      10:10,}\n",
    "        dict_model = {1:\"./saved_models/50_%s_merged_train_bin_1\" % (model_name),\n",
    "                      3:\"./saved_models/50_%s_merged_train_bin_3\" % (model_name),\n",
    "                      6:\"./saved_models/50_%s_merged_train_bin_6\" % (model_name),\n",
    "                      10:\"./saved_models/50_%s_merged_train_bin_10\" % (model_name),}\n",
    "        dict_data = {1:\"./dataset/%s_merged_expr_bin_1\" % (dataset),\n",
    "                     3:\"./dataset/%s_merged_expr_bin_3\" % (dataset),\n",
    "                     6:\"./dataset/%s_merged_expr_bin_6\" % (dataset),\n",
    "                     10:\"./dataset/%s_merged_expr_bin_10\" % (dataset),}\n",
    "        dict_output = {1:\"./outputs/pickle_%s_%s_bin_1\" % (model_name, dataset),\n",
    "                       3:\"./outputs/pickle_%s_%s_bin_3\" % (model_name, dataset),\n",
    "                       6:\"./outputs/pickle_%s_%s_bin_6\" % (model_name, dataset),\n",
    "                       10:\"./outputs/pickle_%s_%s_bin_10\" % (model_name, dataset),}\n",
    "        dict_net = {\"VGG\" : models.vgg19_bn,\n",
    "                    \"ResNet\" : models.resnet18,\n",
    "                    \"MLP\" : MLP}\n",
    "        gen_pickle(1, model_name)\n",
    "        #gen_pickle(3, model_name)\n",
    "        gen_pickle(6, model_name)\n",
    "        gen_pickle(10, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ce7454_training_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
