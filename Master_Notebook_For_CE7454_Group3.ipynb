{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE7454 2019 Project -- Group 3\n",
    "\n",
    "**Add the full name here**\n",
    "\n",
    "Please find all the models and data at [https://github.com/occia/ce7454-group3-project](https://github.com/occia/ce7454-group3-project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from random import randint\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Description\n",
    "\n",
    "Here briefly introduces the background, and throw out the 2 preject questions:\n",
    "- How accurate the modern neural network models could be? (How to relate this with the Identity Acquisition?)\n",
    "- What's the performance of age authentication (below/above 18) for current neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Acquisition\n",
    "\n",
    "\n",
    "For the project, we prepare 2 kinds of data:\n",
    "- training data\n",
    "- validation/testing data\n",
    "\n",
    "Due to the requirement of the large amount of labeled data, we merged 3 existing labeled benchmark datasets as our training data, including [All-Age-Faces](https://github.com/JingchunCheng/All-Age-Faces-Dataset), [FGNET](https://yanweifu.github.io/FG_NET_data/index.html), [UTK Face](https://susanqq.github.io/UTKFace).\n",
    "\n",
    "In total, the amount of labelled images from these 3 benchmarks is 38000, 32818 is used for training and 5182 is used for validation/testing.\n",
    "\n",
    "// **And need to talk about the instagram data**\n",
    "// **For instagram data, we need to show some code snippets about the data scraper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Exploration\n",
    "\n",
    "// **add the age distribution graph for 38000**\n",
    "\n",
    "// **add the age distribution graph for 1900+ instagram data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Preprocessing\n",
    "\n",
    "// **this section should describe the bin-size splitting thing, section 3 will use that**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models and Training\n",
    "\n",
    "In this section, we discuss the choosen models, the training configurations for each model, and the whole training pipeline. The outputs of this section are the saved trained weights for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Selection\n",
    "\n",
    "We targeted on 3 representative models in face recognition and age prediction, the MLP, VGG, and ResNet.\n",
    "\n",
    "As there are many variants of these networks, the first thing is to determine which variants of these model are suitable for our project. \n",
    "We probed ResNet18, ResNet50, ResNet152 using parts of the training data (around 10,000) and found that the performance has no big difference. \n",
    "Thus we made the following selection:\n",
    "- ResNet18, resnet with 18 layers\n",
    "- VGG19_bn, vgg 19 layers with batch normalization\n",
    "- MLP18, 18-layer mlp\n",
    "\n",
    "The ResNet and VGG models can directly imported using the following statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision.models import vgg19_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the MLP model is implemented by ourself and you can find it in the `./src/neural_network/mlp.py` in the [project github](https://github.com/occia/ce7454-group3-project).\n",
    "\n",
    "For demo usage, here is a smaller version MLP implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class is for demo use\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size2, hidden_size3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size3, hidden_size4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size4, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Training Parameters Setup\n",
    "\n",
    "We keep the following training configuration for all 3 choosen models:\n",
    "- Learning Rate, the initial value of learning rate is set as `0.001`\n",
    "- Optimizer, using **Adam** rather than **SGD**\n",
    "- Criterion, using `torch.nn.CrossEntropyLoss()`\n",
    "- Epoches, set to 50 as it balances the training time costs and the training consequence\n",
    "- Batch size, set as 256\n",
    "- Image pixels, set as `(3, 200, 200)`, 3 means 3 channels (a.k.a colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# training parameters setup for demo use\n",
    "#\n",
    "\n",
    "#device= torch.device(\"cuda\")\n",
    "device= torch.device(\"cpu\")\n",
    "\n",
    "channels = 3\n",
    "img_pixels = (200,200)\n",
    "lr = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "# loading dataset\n",
    "def loading_dataset(train_dataset, test_dataset):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_pixels),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    img_data_train = torchvision.datasets.ImageFolder(root=train_dataset, transform=transform)\n",
    "    data_loader_train = torch.utils.data.DataLoader(img_data_train, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    img_data_val = torchvision.datasets.ImageFolder(root=test_dataset, transform=transform)\n",
    "    data_loader_val = torch.utils.data.DataLoader(img_data_val, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = data_loader_train\n",
    "    dataloaders['val'] = data_loader_val\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Model Training WorkFlow\n",
    "\n",
    "The workflow is based on the template teacher provided in the class, and is improved in some aspects.\n",
    "\n",
    "Here lists the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# main training workflow\n",
    "#\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    last = since\n",
    "    time_elapsed = since\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            time_elapsed = time.time() - last\n",
    "            last = time.time()\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Time: {:.0f}m {:.0f}s'.format(phase, epoch_loss, epoch_acc, time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "            # deep copy the modeltopk\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the networks are initialized randomly.\n",
    "Also the images of the dataset are shuffled every time.\n",
    "The key different parts of our implementation from the teacher's template are:\n",
    "- we do train & validation for every epoch\n",
    "- based on the validation result, we save the best epoch's weights, and return that instead of the one be trained longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training Pipeline\n",
    "\n",
    "Till now, we know which model to train and how to train a model. To answer the questions we raised at the beginning, we need to train all the combinations of the selected models and the prepared datasets.\n",
    "\n",
    "Thus, the next step is building the training pipeline for all training combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./saved_models\n",
    "\n",
    "def training_and_save_model(net, num_epochs, model_save_name):\n",
    "    net = net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr)\n",
    "    net, _ = train_model(net, dataloaders, criterion, optimizer, num_epochs)\n",
    "    torch.save(net.state_dict(), os.path.join(\"./saved_models/\", model_save_name))\n",
    "\n",
    "#\n",
    "# whole training pipeline\n",
    "#\n",
    "for binsize in [1, 6, 10]:\n",
    "    classes = (100 + binsize - 1) / binsize\n",
    "    \n",
    "    dataloaders = loading_dataset(\"./dataset/merged_train_bin%d\" % (binsize), \"./dataset/merged_test_bin%d\" % (binsize))\n",
    "    \n",
    "    for model in [\"MLP\", \"ResNet\", \"VGG\"]:\n",
    "        if model == \"MLP\":\n",
    "            net = MLP(channels * img_pixels[0] * img_pixels[1], 512, 512, 512, 512, classes)\n",
    "        else if model == \"ResNet\":\n",
    "            net = resnet18(num_classes=classes)\n",
    "        else:\n",
    "            net = vgg19_bn(num_classes=classes)\n",
    "        \n",
    "        print(\"[+] Training for %s with binsize %d dataset started\" % (model, binsize))\n",
    "        \n",
    "        model_save_name = \"%s_%s_merged_train_bin%d\" % (num_epochs, net.__class__.__name__, binsize)\n",
    "        training_and_save_model(net, num_epochs, model_save_name)\n",
    "        \n",
    "        print(\"[+] Training for %s with binsize %d dataset done\" % (model, binsize))\n",
    "\n",
    "        del net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the pipeline code, we saved weights of the best epoch for all the models towards all the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1 Accuracy Comparison Among Models\n",
    "\n",
    "### 4.2 Identity Acquision Accuracy Cross Ages\n",
    "\n",
    "### 4.3 Age Authentication For 18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ce7454] *",
   "language": "python",
   "name": "conda-env-ce7454-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
